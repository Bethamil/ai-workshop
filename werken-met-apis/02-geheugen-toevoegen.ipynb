{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Opdracht 2: Geheugen Toevoegen\n",
        "\n",
        "## üéØ Wat gaan we doen?\n",
        "\n",
        "In dit notebook gaan we geheugen toevoegen aan onze AI! Je leert:\n",
        "- Hoe message history werkt\n",
        "- System, User en Assistant messages\n",
        "- Een chatbot met geheugen bouwen\n",
        "- Verschillende persoonlijkheden maken\n",
        "\n",
        "## üß† Het Geheim: Message Lists\n",
        "\n",
        "Tot nu toe stuurden we maar √©√©n bericht tegelijk. Voor geheugen sturen we een **lijst** van berichten!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load the .env file from the same directory as the notebook\n",
        "load_dotenv()\n",
        "\n",
        "# Get configuration from environment variables\n",
        "API_KEY = os.getenv('API_KEY', 'ollama')\n",
        "BASE_URL = os.getenv('BASE_URL', 'http://localhost:11434/v1')\n",
        "MODEL = os.getenv('MODEL', 'llama2')\n",
        "\n",
        "print(f\"üîó Configuratie: {BASE_URL}\")\n",
        "print(f\"üîë API Key: {'*' * 8 + API_KEY[-4:] if API_KEY and len(API_KEY) > 4 else 'Niet ingesteld'}\")\n",
        "print(f\"ü§ñ Model: {MODEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≠ De 3 Message Types\n",
        "\n",
        "- **`system`**: Instructies voor de AI (\"Je bent een piraat\")\n",
        "- **`user`**: Wat jij zegt\n",
        "- **`assistant`**: Wat de AI zegt\n",
        "\n",
        "Laten we dit testen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'message': 'model \"llama2\" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     12\u001b[39m     response2 = client.chat.completions.create(\n\u001b[32m     13\u001b[39m         model=MODEL,\n\u001b[32m     14\u001b[39m         messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWat is mijn naam?\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m     15\u001b[39m         max_tokens=\u001b[32m50\u001b[39m\n\u001b[32m     16\u001b[39m     )\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAI (tweede vraag):\u001b[39m\u001b[33m\"\u001b[39m, response2.choices[\u001b[32m0\u001b[39m].message.content)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mtest_zonder_geheugen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtest_zonder_geheugen\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_zonder_geheugen\u001b[39m():\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Eerste vraag\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     response1 = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMijn naam is Alex. Onthoud dit goed!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAI (eerste vraag):\u001b[39m\u001b[33m\"\u001b[39m, response1.choices[\u001b[32m0\u001b[39m].message.content)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Tweede vraag - ZONDER de eerste vraag\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/courses/ai-workshop/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/courses/ai-workshop/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/courses/ai-workshop/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/courses/ai-workshop/.venv/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'model \"llama2\" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}"
          ]
        }
      ],
      "source": [
        "# Test: AI zonder geheugen (zoals notebook 1)\n",
        "def test_zonder_geheugen():\n",
        "    # Eerste vraag\n",
        "    response1 = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Mijn naam is Alex. Onthoud dit goed!\"}],\n",
        "        max_tokens=50\n",
        "    )\n",
        "    print(\"AI (eerste vraag):\", response1.choices[0].message.content)\n",
        "    \n",
        "    # Tweede vraag - ZONDER de eerste vraag\n",
        "    response2 = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Wat is mijn naam?\"}],\n",
        "        max_tokens=50\n",
        "    )\n",
        "    print(\"AI (tweede vraag):\", response2.choices[0].message.content)\n",
        "\n",
        "test_zonder_geheugen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test: AI MET geheugen\n",
        "def test_met_geheugen():\n",
        "    # Maak een message history lijst\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"Mijn naam is Alex. Onthoud dit goed!\"},\n",
        "    ]\n",
        "    \n",
        "    # Eerste API call\n",
        "    response1 = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        max_tokens=50\n",
        "    )\n",
        "    ai_response1 = response1.choices[0].message.content\n",
        "    print(\"AI (eerste vraag):\", ai_response1)\n",
        "    \n",
        "    # Voeg AI antwoord toe aan geschiedenis\n",
        "    messages.append({\"role\": \"assistant\", \"content\": ai_response1})\n",
        "    \n",
        "    # Voeg nieuwe gebruiker vraag toe\n",
        "    messages.append({\"role\": \"user\", \"content\": \"Wat is mijn naam?\"})\n",
        "    \n",
        "    # Tweede API call - NU MET alle voorgeschiedenis!\n",
        "    response2 = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        max_tokens=50\n",
        "    )\n",
        "    print(\"AI (tweede vraag):\", response2.choices[0].message.content)\n",
        "    \n",
        "    print(\"\\nüìã Volledige message history:\")\n",
        "    for i, msg in enumerate(messages):\n",
        "        print(f\"{i+1}. [{msg['role'].upper()}]: {msg['content'][:50]}...\")\n",
        "\n",
        "test_met_geheugen()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Chatbot Class Maken\n",
        "\n",
        "Laten we dit netjes organiseren in een class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleChatbot:\n",
        "    def __init__(self):\n",
        "        self.messages = []  # Dit is ons geheugen!\n",
        "        \n",
        "        # Voeg een system message toe\n",
        "        self.messages.append({\n",
        "            \"role\": \"system\", \n",
        "            \"content\": \"Je bent een vriendelijke AI assistent.\"\n",
        "        })\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        # Voeg user message toe aan geheugen\n",
        "        self.messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_input\n",
        "        })\n",
        "        \n",
        "        # Krijg AI response\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=self.messages,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        \n",
        "        ai_response = response.choices[0].message.content\n",
        "        \n",
        "        # Voeg AI response toe aan geheugen\n",
        "        self.messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": ai_response\n",
        "        })\n",
        "        \n",
        "        return ai_response\n",
        "    \n",
        "    def show_history(self):\n",
        "        print(\"\\nüìú Conversatie History:\")\n",
        "        for i, msg in enumerate(self.messages):\n",
        "            role = msg['role'].upper()\n",
        "            content = msg['content'][:60] + \"...\" if len(msg['content']) > 60 else msg['content']\n",
        "            print(f\"{i+1}. [{role}]: {content}\")\n",
        "        print()\n",
        "\n",
        "# Test de chatbot\n",
        "bot = SimpleChatbot()\n",
        "\n",
        "print(bot.chat(\"Hallo! Ik ben Sarah.\"))\n",
        "print(\"\\n\" + \"-\" * 40)\n",
        "print(bot.chat(\"Wat is mijn naam?\"))\n",
        "print(\"\\n\" + \"-\" * 40)\n",
        "print(bot.chat(\"Vertel iets over programmeren\"))\n",
        "\n",
        "bot.show_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≠ Persoonlijkheden met System Messages\n",
        "\n",
        "Het echte geheim zit in de **system message**. Die bepaalt hoe je AI zich gedraagt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PersonalityBot:\n",
        "    def __init__(self, personality=\"default\"):\n",
        "        self.messages = []\n",
        "        self.set_personality(personality)\n",
        "    \n",
        "    def set_personality(self, personality):\n",
        "        personalities = {\n",
        "            \"default\": \"Je bent een vriendelijke AI assistent.\",\n",
        "            \"piraat\": \"Je bent een stoere piraat! Praat altijd met 'arr' en 'matey'. Vertel verhalen over de zee!\",\n",
        "            \"professor\": \"Je bent een wijze professor. Leg alles uit alsof je lesgeeft. Gebruik voorbeelden.\",\n",
        "            \"rapper\": \"Yo! Je bent een coole rapper. Probeer te rijmen en gebruik straattaal. Stay fresh!\",\n",
        "            \"robot\": \"BEEP BOOP. JE BENT EEN ROBOT. PRAAT. ZOALS. EEN. MACHINE. GEBRUIK. ALLEEN. HOOFDLETTERS.\"\n",
        "        }\n",
        "        \n",
        "        if personality in personalities:\n",
        "            # Reset berichten en zet nieuwe persoonlijkheid\n",
        "            self.messages = [{\n",
        "                \"role\": \"system\",\n",
        "                \"content\": personalities[personality]\n",
        "            }]\n",
        "            print(f\"üé≠ Persoonlijkheid: {personality}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Onbekende persoonlijkheid. Kies uit: {list(personalities.keys())}\")\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=self.messages,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        \n",
        "        ai_response = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "        \n",
        "        return ai_response\n",
        "\n",
        "# Test verschillende persoonlijkheden\n",
        "print(\"üè¥‚Äç‚ò†Ô∏è PIRAAT:\")\n",
        "piraat = PersonalityBot(\"piraat\")\n",
        "print(piraat.chat(\"Hoe gaat het met je?\"))\n",
        "\n",
        "print(\"\\nüéì PROFESSOR:\")\n",
        "prof = PersonalityBot(\"professor\")\n",
        "print(prof.chat(\"Wat is Python?\"))\n",
        "\n",
        "print(\"\\nü§ñ ROBOT:\")\n",
        "robot = PersonalityBot(\"robot\")\n",
        "print(robot.chat(\"Vertel over jezelf\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° EXPERIMENTEER TIJD!\n",
        "\n",
        "**JOUW BEURT:** Maak jouw eigen unieke persoonlijkheid!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JOUW OPDRACHT: Maak een eigen persoonlijkheid!\n",
        "# Idee√´n:\n",
        "# - Een detective die alles mysterieus maakt\n",
        "# - Een chef die alleen over eten praat\n",
        "# - Een time traveler uit de middeleeuwen\n",
        "# - Een alien die Earth probeert te begrijpen\n",
        "# - Een superheld die altijd dramatisch doet\n",
        "\n",
        "class MijnPersonalityBot:\n",
        "    def __init__(self):\n",
        "        self.messages = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"SCHRIJF HIER JOUW EIGEN SYSTEM MESSAGE!\"  # TODO: Vervang dit!\n",
        "        }]\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        \n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=self.messages,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        \n",
        "        ai_response = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "        \n",
        "        return ai_response\n",
        "\n",
        "# Test jouw persoonlijkheid hier:\n",
        "# mijn_bot = MijnPersonalityBot()\n",
        "# print(mijn_bot.chat(\"Hallo! Wie ben jij?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Memory Management\n",
        "\n",
        "**Probleem:** Als gesprekken lang worden, wordt de message list h√©√©l groot. Dan krijg je errors!\n",
        "\n",
        "**Oplossing:** Memory management - oude berichten weggooien:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmartMemoryBot:\n",
        "    def __init__(self, max_messages=10):\n",
        "        self.max_messages = max_messages\n",
        "        self.messages = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Je bent een slimme AI met geheugen. Je onthoudt belangrijke dingen.\"\n",
        "        }]\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        # Voeg user message toe\n",
        "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "        \n",
        "        # Geheugen beheren VOOR API call\n",
        "        self._manage_memory()\n",
        "        \n",
        "        # API call\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=self.messages,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        \n",
        "        ai_response = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "        \n",
        "        return ai_response\n",
        "    \n",
        "    def _manage_memory(self):\n",
        "        \"\"\"Houd alleen de system message + laatste berichten\"\"\"\n",
        "        if len(self.messages) <= self.max_messages:\n",
        "            return  # Nog niet te veel berichten\n",
        "        \n",
        "        # Bewaar system message (eerste)\n",
        "        system_msg = self.messages[0]\n",
        "        \n",
        "        # Houd alleen laatste berichten\n",
        "        recent_messages = self.messages[-(self.max_messages-1):]\n",
        "        \n",
        "        # Update messages\n",
        "        self.messages = [system_msg] + recent_messages\n",
        "        \n",
        "        print(f\"üß† Geheugen opgeruimd! Nu {len(self.messages)} berichten.\")\n",
        "    \n",
        "    def count_messages(self):\n",
        "        user_msgs = sum(1 for msg in self.messages if msg['role'] == 'user')\n",
        "        ai_msgs = sum(1 for msg in self.messages if msg['role'] == 'assistant')\n",
        "        system_msgs = sum(1 for msg in self.messages if msg['role'] == 'system')\n",
        "        \n",
        "        print(f\"üìä Messages: {user_msgs} user, {ai_msgs} AI, {system_msgs} system (totaal: {len(self.messages)})\")\n",
        "\n",
        "# Test memory management\n",
        "memory_bot = SmartMemoryBot(max_messages=6)  # Heel klein voor demo\n",
        "\n",
        "vragen = [\n",
        "    \"Mijn naam is Kim\",\n",
        "    \"Ik woon in Amsterdam\", \n",
        "    \"Mijn hobby is programmeren\",\n",
        "    \"Wat is mijn naam?\",\n",
        "    \"Waar woon ik?\",\n",
        "    \"Wat is mijn hobby?\",\n",
        "    \"Vertel alles wat je over mij weet\"\n",
        "]\n",
        "\n",
        "for vraag in vragen:\n",
        "    print(f\"\\nüë§ User: {vraag}\")\n",
        "    antwoord = memory_bot.chat(vraag)\n",
        "    print(f\"ü§ñ AI: {antwoord}\")\n",
        "    memory_bot.count_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Context Switching\n",
        "\n",
        "Laten we experimenteren met het veranderen van persoonlijkheid tijdens een gesprek:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ContextSwitchBot:\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []  # Bewaar alles\n",
        "        self.current_personality = \"default\"\n",
        "        self._set_system_message(\"default\")\n",
        "    \n",
        "    def _set_system_message(self, personality):\n",
        "        personalities = {\n",
        "            \"default\": \"Je bent een normale AI assistent.\",\n",
        "            \"excited\": \"JE BENT SUPER ENTHOUSIAST! Alles is GEWELDIG! Gebruik veel uitroeptekens!!!\",\n",
        "            \"sleepy\": \"Je bent heel moe... *gaaap*... probeer wakker te blijven maar je bent zo slaperig...\",\n",
        "            \"wise\": \"Je bent een wijze oude man. Spreek langzaam en filosofisch. 'Hmm, interessant...'\"\n",
        "        }\n",
        "        \n",
        "        self.current_personality = personality\n",
        "        self.system_message = personalities.get(personality, personalities[\"default\"])\n",
        "    \n",
        "    def switch_personality(self, new_personality):\n",
        "        self._set_system_message(new_personality)\n",
        "        print(f\"üé≠ Persoonlijkheid gewijzigd naar: {new_personality}\")\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        # Voeg toe aan volledige geschiedenis\n",
        "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        \n",
        "        # Maak messages voor API call met huidige persoonlijkheid\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": self.system_message}\n",
        "        ]\n",
        "        \n",
        "        # Voeg recente geschiedenis toe (laatste 6 berichten)\n",
        "        recent_history = self.conversation_history[-6:]\n",
        "        messages.extend(recent_history)\n",
        "        \n",
        "        # API call\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            max_tokens=150\n",
        "        )\n",
        "        \n",
        "        ai_response = response.choices[0].message.content\n",
        "        self.conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
        "        \n",
        "        return ai_response\n",
        "\n",
        "# Test context switching\n",
        "switch_bot = ContextSwitchBot()\n",
        "\n",
        "print(\"=== NORMALE PERSOONLIJKHEID ===\")\n",
        "print(switch_bot.chat(\"Hallo! Hoe gaat het?\"))\n",
        "\n",
        "switch_bot.switch_personality(\"excited\")\n",
        "print(\"\\n=== ENTHOUSIASTE PERSOONLIJKHEID ===\")\n",
        "print(switch_bot.chat(\"Vertel over je dag\"))\n",
        "\n",
        "switch_bot.switch_personality(\"sleepy\")\n",
        "print(\"\\n=== SLAPERIGE PERSOONLIJKHEID ===\")\n",
        "print(switch_bot.chat(\"Ben je moe?\"))\n",
        "\n",
        "switch_bot.switch_personality(\"wise\")\n",
        "print(\"\\n=== WIJZE PERSOONLIJKHEID ===\")\n",
        "print(switch_bot.chat(\"Wat is de zin van het leven?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù JOUW GROTE OPDRACHT\n",
        "\n",
        "**CHALLENGE:** Bouw jouw eigen multi-persoonlijkheid chatbot! \n",
        "\n",
        "**Vereisten:**\n",
        "1. Minstens 3 verschillende persoonlijkheden\n",
        "2. Geheugen dat belangrijke info onthoudt\n",
        "3. Een functie om persoonlijkheid te switchen\n",
        "4. Memory management voor lange gesprekken\n",
        "\n",
        "**EXTRA PUNTEN:**\n",
        "- Voeg emoji's toe aan responses\n",
        "- Maak een \"mood\" system (vrolijk, boos, verdrietig)\n",
        "- Laat de AI automatisch van persoonlijkheid wisselen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JOUW EIGEN MULTI-PERSOONLIJKHEID CHATBOT HIER!\n",
        "# Start met deze template:\n",
        "\n",
        "class MijnUltimateBot:\n",
        "    def __init__(self):\n",
        "        self.messages = []\n",
        "        self.personalities = {\n",
        "            # TODO: Voeg jouw eigen persoonlijkheden toe!\n",
        "            \"default\": \"Je bent een vriendelijke assistent.\",\n",
        "            # \"jouw_persoonlijkheid\": \"Beschrijving hier...\"\n",
        "        }\n",
        "        self.current_personality = \"default\"\n",
        "        self._reset_with_personality(\"default\")\n",
        "    \n",
        "    def _reset_with_personality(self, personality):\n",
        "        # TODO: Implementeer dit\n",
        "        pass\n",
        "    \n",
        "    def switch_personality(self, personality):\n",
        "        # TODO: Implementeer persoonlijkheid switchen\n",
        "        pass\n",
        "    \n",
        "    def chat(self, user_input):\n",
        "        # TODO: Implementeer chat met geheugen\n",
        "        pass\n",
        "    \n",
        "    def show_stats(self):\n",
        "        # TODO: Toon interessante statistieken\n",
        "        pass\n",
        "\n",
        "# Test jouw bot hier:\n",
        "# mijn_bot = MijnUltimateBot()\n",
        "# print(mijn_bot.chat(\"Hallo!\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Check Jezelf\n",
        "\n",
        "Kun je deze vragen beantwoorden?\n",
        "\n",
        "1. **Wat is het verschil tussen `system`, `user` en `assistant` messages?**\n",
        "2. **Waarom is memory management belangrijk?**\n",
        "3. **Hoe zou je een AI maken die boos wordt als je onbeleefde dingen zegt?**\n",
        "4. **Wat gebeurt er als je message list te lang wordt?**\n",
        "\n",
        "Schrijf je antwoorden hieronder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Mijn antwoorden:**\n",
        "\n",
        "1. Message types: \n",
        "2. Memory management: \n",
        "3. Boze AI: \n",
        "4. Te lange lijst: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Volgende Stap\n",
        "\n",
        "Wauw! Nu heb je een AI met geheugen √©n persoonlijkheid gemaakt! In het volgende notebook gaan we meerdere AI's met elkaar laten praten.\n",
        "\n",
        "**Ga naar: [03-ai-conversaties.ipynb](03-ai-conversaties.ipynb)**\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Tips voor Thuis\n",
        "\n",
        "- **System messages zijn super krachtig** - experimenteer ermee!\n",
        "- **Bewaar belangrijke info** in je memory management\n",
        "- **Test met lange gesprekken** om je memory limits te vinden\n",
        "- **Maak gekke persoonlijkheden** - dat is het leukste!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}