{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üì± Opdracht 1: Je Eerste AI API Call\n",
        "\n",
        "## üéØ Wat gaan we doen?\n",
        "\n",
        "In dit notebook maken we onze eerste verbinding met een AI API. Je leert:\n",
        "- Verbinding maken met verschillende AI providers\n",
        "- Je eerste AI chat message versturen\n",
        "- Responses ontvangen en begrijpen\n",
        "\n",
        "## üõ†Ô∏è Setup\n",
        "\n",
        "Eerst installeren we de benodigde packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installeer benodigde packages\n",
        "!pip install openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë API Configuration\n",
        "\n",
        "We gaan verschillende providers proberen. Kies er √©√©n:\n",
        "\n",
        "### Optie 1: OpenAI (officieel)\n",
        "- Ga naar [OpenAI Platform](https://platform.openai.com/api-keys)\n",
        "- Maak een API key aan\n",
        "\n",
        "### Optie 2: OpenRouter (meerdere modellen)\n",
        "- Ga naar [OpenRouter](https://openrouter.ai/)\n",
        "- Maak een account en haal je API key op\n",
        "- Toegang tot veel verschillende modellen!\n",
        "\n",
        "### Optie 3: Ollama (lokaal)\n",
        "- Installeer [Ollama](https://ollama.ai)\n",
        "- Download een model: `ollama pull llama2`\n",
        "- Start de server: `ollama serve`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load the .env file from the same directory as the notebook\n",
        "load_dotenv()\n",
        "\n",
        "# Get configuration from environment variables\n",
        "API_KEY = os.getenv('API_KEY', 'ollama')\n",
        "BASE_URL = os.getenv('BASE_URL', 'http://localhost:11434/v1')\n",
        "MODEL = os.getenv('MODEL', 'llama2')\n",
        "\n",
        "print(f\"üîó Configuratie: {BASE_URL}\")\n",
        "print(f\"üîë API Key: {'*' * 8 + API_KEY[-4:] if API_KEY and len(API_KEY) > 4 else 'Niet ingesteld'}\")\n",
        "print(f\"ü§ñ Model: {MODEL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialise de AI client\n",
        "client = OpenAI(\n",
        "    api_key=API_KEY,\n",
        "    base_url=BASE_URL\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Je Eerste API Call\n",
        "\n",
        "Nu maken we verbinding met de AI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test je eerste API call!\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hallo! Wat is je naam?\"}\n",
        "    ],\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "print(\"AI Response:\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Experimenteer Tijd!\n",
        "\n",
        "**JOUW BEURT:** Probeer verschillende vragen uit. Verander de message content hieronder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXPERIMENTEER: verander deze vraag!\n",
        "vraag = \"Vertel me een grappige mop over programmeurs\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": vraag}\n",
        "    ],\n",
        "    max_tokens=150\n",
        ")\n",
        "\n",
        "print(f\"Vraag: {vraag}\")\n",
        "print(f\"AI: {response.choices[0].message.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéõÔ∏è Parameters Experimenteren\n",
        "\n",
        "De API heeft verschillende parameters. Probeer ze uit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experimenteer met verschillende parameters\n",
        "def test_parameter(temperature=0.7, max_tokens=100):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Schrijf een kort gedicht over de zee\"}\n",
        "        ],\n",
        "        temperature=temperature,  # 0.0 = voorspelbaar, 1.0 = creatief\n",
        "        max_tokens=max_tokens     # Maximum woorden in antwoord\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "print(\"üå°Ô∏è Temperature 0.1 (voorspelbaar):\")\n",
        "print(test_parameter(temperature=0.1))\n",
        "print(\"\\nüå°Ô∏è Temperature 0.9 (creatief):\")\n",
        "print(test_parameter(temperature=0.9))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Interactieve Chat Functie\n",
        "\n",
        "Laten we een eenvoudige chat functie maken:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_with_ai(message):\n",
        "    \"\"\"Stuur een bericht naar de AI en krijg een antwoord terug\"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": message}],\n",
        "            max_tokens=200,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Test de functie\n",
        "antwoord = chat_with_ai(\"Leg in √©√©n zin uit wat machine learning is\")\n",
        "print(f\"AI: {antwoord}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù JOUW OPDRACHT\n",
        "\n",
        "Nu is het jouw beurt om te experimenteren! Probeer het volgende:\n",
        "\n",
        "1. **Test verschillende providers** - Probeer OpenAI, OpenRouter √©n Ollama\n",
        "2. **Experimenteer met modellen** - Als je OpenRouter gebruikt, probeer verschillende modellen\n",
        "3. **Speel met parameters** - Test verschillende temperature waarden\n",
        "4. **Maak het persoonlijk** - Stel vragen over jouw interesses\n",
        "\n",
        "**CHALLENGE:** Maak hieronder jouw eigen AI assistent met een specifieke persoonlijkheid!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# JOUW CODE HIER - Experimenteer vrij!\n",
        "# Idee√´n:\n",
        "# - Maak een AI die alleen in vragen antwoordt\n",
        "# - Een AI die alles ramt zoals een piraat\n",
        "# - Een AI die heel kort antwoordt (max 20 woorden)\n",
        "# - Een AI expert in jouw hobby/werk\n",
        "\n",
        "def mijn_ai_assistent(vraag):\n",
        "    # TODO: Schrijf hier jouw eigen AI assistent!\n",
        "    pass\n",
        "\n",
        "# Test jouw assistent hier:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Provider Vergelijking\n",
        "\n",
        "Als je meerdere providers hebt geconfigureerd, vergelijk ze:\n",
        "\n",
        "Pas je .env bestand aan om een andere provider of model te kiezen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vergelijk verschillende providers/modellen\n",
        "test_vraag = \"Wat is het verschil tussen Python en JavaScript?\"\n",
        "\n",
        "chat_with_ai(test_vraag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Check jezelf\n",
        "\n",
        "Kun je deze vragen beantwoorden?\n",
        "\n",
        "1. **Wat doet de `temperature` parameter?**\n",
        "2. **Wat is het verschil tussen OpenAI, OpenRouter en Ollama?**\n",
        "3. **Hoe zou je een AI maken die altijd kort antwoordt?**\n",
        "\n",
        "Schrijf je antwoorden hieronder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Mijn antwoorden:**\n",
        "\n",
        "1. Temperature: \n",
        "2. Providers: \n",
        "3. Korte antwoorden: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Volgende Stap\n",
        "\n",
        "Geweldig! Je hebt je eerste AI API calls gemaakt. In het volgende notebook gaan we geheugen toevoegen zodat de AI zich eerdere berichten kan herinneren.\n",
        "\n",
        "**Ga naar: [02-geheugen-toevoegen.ipynb](02-geheugen-toevoegen.ipynb)**\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Tips voor Thuis\n",
        "\n",
        "- **OpenRouter** geeft toegang tot veel modellen - experimenteer!\n",
        "- **Ollama** is gratis maar je hebt een goede computer nodig\n",
        "- **Bewaar je API keys veilig** - deel ze nooit online\n",
        "- **Start klein** - complexe prompts komen later"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
